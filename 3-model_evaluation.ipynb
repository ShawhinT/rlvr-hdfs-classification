{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "506a3951-5091-4354-9569-0697bb431de4",
   "metadata": {},
   "source": [
    "# Compare Base vs Fine-Tuned Model\n",
    "\n",
    "Code authored by: Shaw Talebi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff5d633",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3f5e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from functions import run_inference, calculate_metrics, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61048f29",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "921ab4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from HF hub\n",
    "ds = load_dataset(\"shawhin/HDFS_v1_blocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbf27a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 2 anomalous, 48 normal\n"
     ]
    }
   ],
   "source": [
    "num_test = 50\n",
    "test_sample = ds[\"test\"].shuffle(seed=0).select(range(num_test))\n",
    "\n",
    "# check class distribution in samples\n",
    "test_positive = sum(test_sample[\"label\"])\n",
    "\n",
    "print(f\"Test: {test_positive} anomalous, {len(test_sample) - test_positive} normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd633697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab51e545cbb54a09a821d2d712300bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/460048 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5aa873faa9c438385a6b3c04ddb629f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/460048 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split training data by class\n",
    "test_anomalous = ds[\"train\"].filter(lambda x: x[\"label\"] == 1).shuffle(seed=42)\n",
    "test_normal = ds[\"train\"].filter(lambda x: x[\"label\"] == 0).shuffle(seed=42)\n",
    "\n",
    "# Balanced 50-50 split for training\n",
    "test_sample = concatenate_datasets([\n",
    "    test_anomalous.select(range(int(num_test * 0.1))),\n",
    "    test_normal.select(range(int(num_test * 0.9)))\n",
    "]).shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59de0a4",
   "metadata": {},
   "source": [
    "### response format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab3eaa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define structured output schema\n",
    "response_format = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"anomaly_flag\",\n",
    "        \"strict\": True,\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"Anomalous\": {\n",
    "                    \"type\": \"boolean\",\n",
    "                    \"description\": \"True if the log block is anomalous, false otherwise.\"\n",
    "                },\n",
    "                \"reasoning\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Explanation of the decision regarding whether the block is anomalous.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"Anomalous\", \"reasoning\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d42473f",
   "metadata": {},
   "source": [
    "### evaluate base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "107a6af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running o4-mini-2025-04-16: 100%|██████████| 50/50 [05:10<00:00,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model (o4-mini-2025-04-16) metrics:\n",
      "  accuracy: 0.7600\n",
      "  precision: 0.1818\n",
      "  recall: 0.4000\n",
      "  f1: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_model = \"o4-mini-2025-04-16\"\n",
    "\n",
    "# run base model on validation set\n",
    "test_labels = [bool(ex[\"label\"]) for ex in test_sample]\n",
    "\n",
    "base_predictions = run_inference(base_model, test_sample, response_format)\n",
    "base_metrics = calculate_metrics(base_predictions, test_labels)\n",
    "\n",
    "print(f\"Base model ({base_model}) metrics:\")\n",
    "for metric, value in base_metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c905a7",
   "metadata": {},
   "source": [
    "### evaluate fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28eeacb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running ft:o4-mini-2025-04-16:shawhin-talebi-ventures-llc:hdfs-classification:D2XE1CWu: 100%|██████████| 50/50 [05:00<00:00,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model (ft:o4-mini-2025-04-16:shawhin-talebi-ventures-llc:hdfs-classification:D2XE1CWu) metrics:\n",
      "  accuracy: 0.8000\n",
      "  precision: 0.2727\n",
      "  recall: 0.6000\n",
      "  f1: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ft_model = \"ft:o4-mini-2025-04-16:shawhin-talebi-ventures-llc:hdfs-classification:D2XE1CWu\"\n",
    "\n",
    "# run fine-tuned model on validation set\n",
    "ft_predictions = run_inference(ft_model, test_sample, response_format)\n",
    "ft_metrics = calculate_metrics(ft_predictions, test_labels)\n",
    "\n",
    "print(f\"Fine-tuned model ({ft_model}) metrics:\")\n",
    "for metric, value in ft_metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2142b4a",
   "metadata": {},
   "source": [
    "### compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b85f6641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Comparison:\n",
      "                  accuracy  precision  recall     f1\n",
      "Base Model            0.76     0.1818     0.4  0.250\n",
      "Fine-tuned Model      0.80     0.2727     0.6  0.375\n",
      "Improvement           0.04     0.0909     0.2  0.125\n",
      "\n",
      "Confusion Matrices:\n",
      "\n",
      "Base Model:\n",
      "[[36  9]\n",
      " [ 3  2]]\n",
      "\n",
      "Fine-tuned Model:\n",
      "[[37  8]\n",
      " [ 2  3]]\n"
     ]
    }
   ],
   "source": [
    "# compare base vs fine-tuned model\n",
    "comparison = pd.DataFrame({\n",
    "    \"Base Model\": base_metrics,\n",
    "    \"Fine-tuned Model\": ft_metrics\n",
    "}).T\n",
    "\n",
    "# add improvement row\n",
    "improvement = {k: ft_metrics[k] - base_metrics[k] for k in base_metrics}\n",
    "comparison.loc[\"Improvement\"] = improvement\n",
    "\n",
    "print(\"Model Comparison:\")\n",
    "print(comparison.round(4).to_string())\n",
    "\n",
    "print(\"\\nConfusion Matrices:\")\n",
    "print(f\"\\nBase Model:\\n{confusion_matrix(test_labels, base_predictions)}\")\n",
    "print(f\"\\nFine-tuned Model:\\n{confusion_matrix(test_labels, ft_predictions)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
