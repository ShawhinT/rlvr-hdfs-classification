{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d9daab2d-f864-48d7-9442-26013930fd15",
      "metadata": {},
      "source": [
        "# Reinforcement Fine-tuning of o4-mini for Log Classification\n",
        "\n",
        "Code authored by: Shaw Talebi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad46ac26-e29a-4dd3-a13b-036105f62b83",
      "metadata": {},
      "source": [
        "### imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "817a0b7e-cf5c-4cea-9924-391022af6635",
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset, concatenate_datasets\n",
        "import json\n",
        "\n",
        "from functions import run_inference, calculate_metrics, confusion_matrix\n",
        "\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a7b8c9d0-e1f2-3456-7890-123456789abc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import sk from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# connect to openai API\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82dc91bb-4cc0-400c-86c4-f3ed221feb81",
      "metadata": {},
      "source": [
        "## 1) Data Prep"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3de686c5-fcb1-443b-a709-f3238e263599",
      "metadata": {},
      "source": [
        "### load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d683afdb-6be3-4168-98f4-40729de3de14",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['block_id', 'text', 'label'],\n",
              "        num_rows: 460048\n",
              "    })\n",
              "    dev: Dataset({\n",
              "        features: ['block_id', 'text', 'label'],\n",
              "        num_rows: 57506\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['block_id', 'text', 'label'],\n",
              "        num_rows: 57507\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load data from HF hub\n",
        "ds = load_dataset(\"shawhin/HDFS_v1_blocks\")\n",
        "ds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35b1b897-dbb7-4855-83b4-832a5c303bda",
      "metadata": {},
      "source": [
        "### sample train and dev sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training samples: 100\n",
            "Validation samples: 50\n"
          ]
        }
      ],
      "source": [
        "num_train = 100\n",
        "num_val = 50\n",
        "\n",
        "# Split training data by class\n",
        "train_anomalous = ds[\"train\"].filter(lambda x: x[\"label\"] == 1).shuffle(seed=42)\n",
        "train_normal = ds[\"train\"].filter(lambda x: x[\"label\"] == 0).shuffle(seed=42)\n",
        "\n",
        "val_anomalous = ds[\"dev\"].filter(lambda x: x[\"label\"] == 1).shuffle(seed=42)\n",
        "val_normal = ds[\"dev\"].filter(lambda x: x[\"label\"] == 0).shuffle(seed=42)\n",
        "\n",
        "# Balanced 50-50 split for training\n",
        "train_sample = concatenate_datasets([\n",
        "    train_anomalous.select(range(int(num_train/2))),\n",
        "    train_normal.select(range(int(num_train/2)))\n",
        "]).shuffle(seed=42)\n",
        "\n",
        "# Balanced 80-20 split for validation\n",
        "val_sample = concatenate_datasets([\n",
        "    val_anomalous.select(range(int(num_val * 0.2))),\n",
        "    val_normal.select(range(int(num_val * 0.8)))\n",
        "]).shuffle(seed=42)\n",
        "\n",
        "print(f\"Training samples: {len(train_sample)}\")\n",
        "print(f\"Validation samples: {len(val_sample)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b2c3d4e5-f6a7-8901-bcde-f23456789012",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 50 anomalous, 50 normal\n",
            "Val: 10 anomalous, 40 normal\n"
          ]
        }
      ],
      "source": [
        "# check class distribution in samples\n",
        "train_positive = sum(train_sample[\"label\"])\n",
        "val_positive = sum(val_sample[\"label\"])\n",
        "\n",
        "print(f\"Train: {train_positive} anomalous, {len(train_sample) - train_positive} normal\")\n",
        "print(f\"Val: {val_positive} anomalous, {len(val_sample) - val_positive} normal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df57bfc6-df3b-4eba-b840-40040e4b90b0",
      "metadata": {},
      "source": [
        "### format training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c3d4e5f6-a7b8-9012-cdef-345678901234",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "def format_example(example):\n",
        "    \"\"\"Convert a dataset example to OpenAI RFT JSONL format.\"\"\"\n",
        "    return {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"developer\", \"content\": \"Classify this HDFS log block as anomalous or normal.\"},\n",
        "            {\"role\": \"user\", \"content\": example[\"text\"]}\n",
        "        ],\n",
        "        \"label\": bool(example[\"label\"])  # True = anomalous, False = normal\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d4e5f6a7-b8c9-0123-def4-567890123456",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"messages\": [\n",
            "    {\n",
            "      \"role\": \"developer\",\n",
            "      \"content\": \"Classify this HDFS log block as anomalous or normal.\"\n",
            "    },\n",
            "    {\n",
            "      \"role\": \"user\",\n",
            "      \"content\": \"INFO dfs.DataNode$DataXceiver: Receiving block blk_-3662429616261189633 src: /10.251.91.84:35214 dest: /10.251.91.84:50010\\nINFO dfs.DataNode$DataXceiver: Receiving block blk_-3662429616261189633 src: /10.250.6.191:44011 dest: /10.250.6.191:50010\\nINFO dfs.DataNode$DataXceiver: Receiving block blk_-3662429616261189633 src: /10.250.6.191:44448 dest: /10.250.6.191:50010\\nINFO dfs.FSNamesystem: BLOCK* NameSystem.allocateBlock: /user/root/randtxt5/_temporary/_task_200811101024_0012_m_000434_0/part-00434. blk_-3662429616261189633\\nINFO dfs.DataNode$PacketResponder: PacketResponder 0 for block blk_-3662429616261189633 terminating\\nINFO dfs.DataNode$PacketResponder: Received block blk_-3662429616261189633 of size 67108864 from /10.251.91.84\\nINFO dfs.DataNode$PacketResponder: PacketResponder 1 for block blk_-3662429616261189633 terminating\\nINFO dfs.DataNode$PacketResponder: Received block blk_-3662429616261189633 of size 67108864 from /10.250.6.191\\nINFO dfs.DataNode$PacketResponder: PacketResponder 2 for block blk_-3662429616261189633 terminating\\nINFO dfs.DataNode$PacketResponder: Received block blk_-3662429616261189633 of size 67108864 from /10.250.6.191\\nINFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.125.174:50010 is added to blk_-3662429616261189633 size 67108864\\nINFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.91.84:50010 is added to blk_-3662429616261189633 size 67108864\\nINFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.250.6.191:50010 is added to blk_-3662429616261189633 size 67108864\\nINFO dfs.FSNamesystem: BLOCK* NameSystem.delete: blk_-3662429616261189633 is added to invalidSet of 10.250.6.191:50010\\nINFO dfs.FSNamesystem: BLOCK* NameSystem.delete: blk_-3662429616261189633 is added to invalidSet of 10.251.125.174:50010\\nINFO dfs.FSNamesystem: BLOCK* NameSystem.delete: blk_-3662429616261189633 is added to invalidSet of 10.251.91.84:50010\\nINFO dfs.FSDataset: Deleting block blk_-3662429616261189633 file /mnt/hadoop/dfs/data/current/subdir44/blk_-3662429616261189633\\nINFO dfs.FSDataset: Deleting block blk_-3662429616261189633 file /mnt/hadoop/dfs/data/current/subdir1/blk_-3662429616261189633\\nINFO dfs.FSDataset: Deleting block blk_-3662429616261189633 file /mnt/hadoop/dfs/data/current/subdir22/blk_-3662429616261189633\"\n",
            "    }\n",
            "  ],\n",
            "  \"label\": false\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# format training data\n",
        "train_data = [format_example(ex) for ex in train_sample]\n",
        "val_data = [format_example(ex) for ex in val_sample]\n",
        "\n",
        "# preview a sample\n",
        "print(json.dumps(train_data[0], indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e5f6a7b8-c9d0-1234-ef56-789012345678",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote 100 training examples to data/train_rft.jsonl\n",
            "Wrote 50 validation examples to data/val_rft.jsonl\n"
          ]
        }
      ],
      "source": [
        "# write to JSONL files\n",
        "train_file_path = \"data/train_rft.jsonl\"\n",
        "val_file_path = \"data/val_rft.jsonl\"\n",
        "\n",
        "with open(train_file_path, \"w\") as f:\n",
        "    for item in train_data:\n",
        "        f.write(json.dumps(item) + \"\\n\")\n",
        "\n",
        "with open(val_file_path, \"w\") as f:\n",
        "    for item in val_data:\n",
        "        f.write(json.dumps(item) + \"\\n\")\n",
        "\n",
        "print(f\"Wrote {len(train_data)} training examples to {train_file_path}\")\n",
        "print(f\"Wrote {len(val_data)} validation examples to {val_file_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6a7b8c9-d0e1-2345-f678-901234567890",
      "metadata": {},
      "source": [
        "### upload files to OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b8c9d0e1-f234-5678-9012-3456789abcde",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training file ID: file-37hAAqyD6RUbyjhmRynvYw\n",
            "Validation file ID: file-NMJmXjvcbiCE9sqKHyxgKP\n"
          ]
        }
      ],
      "source": [
        "# upload training file\n",
        "with open(train_file_path, \"rb\") as f:\n",
        "    train_file = client.files.create(file=f, purpose=\"fine-tune\")\n",
        "print(f\"Training file ID: {train_file.id}\")\n",
        "\n",
        "# upload validation file\n",
        "with open(val_file_path, \"rb\") as f:\n",
        "    val_file = client.files.create(file=f, purpose=\"fine-tune\")\n",
        "print(f\"Validation file ID: {val_file.id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce5f6e8f-a510-4f93-b0de-26cf8bb22cc0",
      "metadata": {},
      "source": [
        "## 2) Grader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8cef3e2-ac31-432c-9dfe-a43594e417fe",
      "metadata": {},
      "source": [
        "### create grader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c9d0e1f2-3456-7890-1234-56789abcdef0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# define Python grader with asymmetric reward structure\n",
        "# False negatives (missed anomalies) are penalized more heavily than false positives\n",
        "grader = {\n",
        "    \"type\": \"python\",\n",
        "    \"name\": \"custom_reward\",\n",
        "    \"image_tag\": \"2025-05-08\",\n",
        "    \"source\": \"\"\"\n",
        "def grade(sample, item):\n",
        "    try:\n",
        "        pred = sample[\"output_json\"][\"Anomalous\"]  # boolean from structured output\n",
        "        actual = item[\"label\"]  # boolean label from training data\n",
        "        \n",
        "        if pred == actual:\n",
        "            return 1.0  # Correct prediction\n",
        "        elif actual:  # False negative: missed anomaly\n",
        "            return 0.0  # Worst outcome\n",
        "        else:  # False positive: false alarm\n",
        "            return 0.3  # Bad but not as bad\n",
        "    except (KeyError, TypeError):\n",
        "        return 0.0  # Malformed output treated as worst case\n",
        "\"\"\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d0e1f234-5678-9012-3456-789abcdef012",
      "metadata": {},
      "outputs": [],
      "source": [
        "# define structured output schema\n",
        "response_format = {\n",
        "    \"type\": \"json_schema\",\n",
        "    \"json_schema\": {\n",
        "        \"name\": \"anomaly_flag\",\n",
        "        \"strict\": True,\n",
        "        \"schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"Anomalous\": {\n",
        "                    \"type\": \"boolean\",\n",
        "                    \"description\": \"True if the log block is anomalous, false otherwise.\"\n",
        "                },\n",
        "                \"reasoning\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Explanation of the decision regarding whether the block is anomalous.\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"Anomalous\", \"reasoning\"],\n",
        "            \"additionalProperties\": False\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7998bded-aa06-4190-9d85-e0c114726db8",
      "metadata": {},
      "source": [
        "## 3) Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55ff967f-96a6-425a-aa9b-7d7691abfdae",
      "metadata": {},
      "source": [
        "### model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e1f23456-7890-1234-5678-9abcdef01234",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tuning job created: ftjob-FlGliAbBOzj7w1L0C7O3C7DG\n"
          ]
        }
      ],
      "source": [
        "# base model\n",
        "base_model = \"o4-mini-2025-04-16\"\n",
        "\n",
        "# create fine-tuning job with reinforcement learning\n",
        "job = client.fine_tuning.jobs.create(\n",
        "    model=base_model,\n",
        "    suffix = \"hdfs_classification\",\n",
        "    training_file=train_file.id,\n",
        "    validation_file=val_file.id,\n",
        "    method={\n",
        "        \"type\": \"reinforcement\",\n",
        "        \"reinforcement\": {\n",
        "            \"grader\": grader,\n",
        "            \"response_format\": response_format\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "print(f\"Fine-tuning job created: {job.id}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
